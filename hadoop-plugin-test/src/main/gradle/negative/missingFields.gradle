buildscript {
  dependencies {
    classpath files("${project.pluginTestDir}/hadoop-plugin-${project.version}.jar", "${project.pluginTestDir}/hadoop-plugin-${project.version}-SNAPSHOT.jar")
  }
}

apply plugin: com.linkedin.gradle.hadoop.HadoopPlugin

// Negative test for missing required fields.
hadoop {
  buildPath "jobs"
  cleanPath false

  workflow('missingFieldsWorkflow1') {
    propertyFile('properties1') {
    }

    job('job1') {
    }

    commandJob('job2') {
      depends 'job1'
    }

    hadoopJavaJob('job3') {
      depends 'job2'
    }

    hiveJob('job4') {
      depends 'job3'
    }

    javaJob('job5') {
      depends 'job5'
    }

    javaProcessJob('job6') {
      depends 'job5'
    }

    kafkaPushJob('job7') {
      depends 'job6'
    }

    noOpJob('job8') {
      depends 'job7'
    }

    pigJob('job9') {
      depends 'job8'
    }

    sparkJob('job10') {
      depends 'job9'
    }

    sparkJob('job10Jar1') {
      executes 'hello-spark.jar'
      depends 'job10'
    }

    sparkJob('job10Jar2') {
      uses ''
      executes 'hello-spark.jar'
      depends 'job10Jar1'
    }

    sparkJob('job10Py') {
      uses 'com.linkedin.HelloSpark'
      executes 'hello_pyspark.py'
      depends 'job10Jar2'
    }

    voldemortBuildPushJob('job11') {
      depends 'job10Py'
    }

    hadoopShellJob('job12') {
      depends 'job11'
    }

    hdfsToTeradataJob('job13') {
      depends 'job12'
    }

    teradataToHdfsJob('job14') {
      depends 'job13'
    }

    hdfsToEspressoJob('job15') {
      depends 'job14'
    }

    gobblinJob('job16') {
      depends 'job15'
    }

    sqlJob('job17') {
      depends 'job16'
    }

    pinotBuildAndPushJob('job18') {
      depends 'job17'
    }

    tableauJob('job19') {
      depends 'job18'
    }

    targets 'job19'
  }
}
